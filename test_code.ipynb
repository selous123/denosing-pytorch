{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "height = width = 16\n",
    "\n",
    "height_gap = 2 / (height - 1)\n",
    "width_gap = 2 / (width - 1)\n",
    "height, width = torch.meshgrid([torch.range(-1, 1, height_gap), torch.Tensor(1)])\n",
    "\n",
    "print(torch.range(-1, 1, height_gap))\n",
    "print(height)\n",
    "\n",
    "print(width)\n",
    "\n",
    "lr_identity = torch.stack([width, height])\n",
    "\n",
    "\n",
    "print(lr_identity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "a['b'] = 2\n",
    "a['c'] = 10\n",
    "\n",
    "for k,v in a.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "def func(a):\n",
    "    yield a[0], a[1], a[2], a[3]\n",
    "    \n",
    "for i in func(a):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "print(set(a))\n",
    "def func(a):\n",
    "    yield a[0]\n",
    "    for i in range(len(a[1:])):\n",
    "        yield a[i]\n",
    "    \n",
    "for i in func(a):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = True\n",
    "b = True\n",
    "\n",
    "a and b\n",
    "\n",
    "\n",
    "import random\n",
    "a = random.random()\n",
    "print(a < 0.5)\n",
    "\n",
    "b = b and random.random() < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "idx_data = 0\n",
    "a = torch.rand([5,2,7])\n",
    "print(a)\n",
    "b, epoch_idx = a.max(0)\n",
    "best, frame_idx = b.max(1)\n",
    "print(epoch_idx)\n",
    "print(best)\n",
    "print(frame_idx)\n",
    "\n",
    "\n",
    "best_frame_idx = frame_idx[idx_data]\n",
    "print(best_frame_idx)\n",
    "best_epoch_idx = epoch_idx[idx_data, frame_idx[idx_data]]\n",
    "print(best_epoch_idx)\n",
    "\n",
    "print(a[best_epoch_idx, idx_data, best_frame_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '10'\n",
    "\n",
    "try:\n",
    "    print(\"frame\" + str(a))\n",
    "except:\n",
    "    raise TypeError(\"a should be int type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand([5,2,7])\n",
    "\n",
    "print(a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "for idx, i in enumerate(tqdm(np.arange(100))):\n",
    "    print(idx)\n",
    "    sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([3,4,5])\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(\"a is {}\".format(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "TAG_FLOAT = 202021.25\n",
    "import torch.nn as nn\n",
    "def read_flow(file):\n",
    "\n",
    "    assert type(file) is str, \"file is not str %r\" % str(file)\n",
    "    assert os.path.isfile(file) is True, \"file does not exist %r\" % str(file)\n",
    "    assert file[-4:] == '.flo', \"file ending is not .flo %r\" % file[-4:]\n",
    "    f = open(file,'rb')\n",
    "    flo_number = np.fromfile(f, np.float32, count=1)[0]\n",
    "    assert flo_number == TAG_FLOAT, 'Flow number %r incorrect. Invalid .flo file' % flo_number\n",
    "    w = np.fromfile(f, np.int32, count=1)\n",
    "    h = np.fromfile(f, np.int32, count=1)\n",
    "    data = np.fromfile(f, np.float32, count=2*w[0]*h[0])\n",
    "    #if error try: data = np.fromfile(f, np.float32, count=2*w*h)\n",
    "    # Reshape data into 3D array (columns, rows, bands)\n",
    "    flow = np.resize(data, (int(h), int(w), 2))\n",
    "    f.close()\n",
    "\n",
    "    return flow\n",
    "\n",
    "def warp(x, flo):\n",
    "    \"\"\"\n",
    "    warp an image/tensor (im2) back to im1, according to the optical flow.\n",
    "    Code heavily inspired by\n",
    "    x: [B, C, H, W] (im2)\n",
    "    flo: [B, 2, H, W] flow\n",
    "    \"\"\"\n",
    "    B, C, H, W = x.size()\n",
    "    # mesh grid\n",
    "    xx = torch.arange(0, W).view(1, -1).repeat(H, 1)\n",
    "    yy = torch.arange(0, H).view(-1, 1).repeat(1, W)\n",
    "    xx = xx.view(1, 1, H, W).repeat(B, 1, 1, 1)\n",
    "    yy = yy.view(1, 1, H, W).repeat(B, 1, 1, 1)\n",
    "    grid = torch.cat((xx, yy), 1).float()\n",
    "    #print(grid)\n",
    "    grid = grid\n",
    "    vgrid = grid + flo\n",
    "\n",
    "    # scale grid to [-1,1]\n",
    "    vgrid[:, 0, :, :] = 2.0*vgrid[:, 0, :, :]/max(W-1, 1)-1.0\n",
    "    vgrid[:, 1, :, :] = 2.0*vgrid[:, 1, :, :]/max(H-1, 1)-1.0\n",
    "    vgrid = vgrid.permute(0, 2, 3, 1)\n",
    "    output = nn.functional.grid_sample(x, vgrid)\n",
    "    # Define a first mask containing pixels that wasn't properly interpolated\n",
    "    mask = torch.autograd.Variable(torch.ones(x.size()))\n",
    "    mask = nn.functional.grid_sample(mask, vgrid)\n",
    "    mask[mask < 0.9999] = 0\n",
    "    mask[mask > 0] = 1\n",
    "\n",
    "    return output, mask\n",
    "\n",
    "\n",
    "filename = \"/home/lrh/git/blind-denoising/tvl1flow/of/tvl1_target.flo\"\n",
    "\n",
    "of = read_flow(filename)\n",
    "print(of.max())\n",
    "print(of.min())\n",
    "\n",
    "print(of.shape)\n",
    "\n",
    "of = torch.tensor(of).unsqueeze(0).permute(0,3,1,2)\n",
    "\n",
    "image_path = \"/home/lrh/git/blind-denoising/tvl1flow/image/target/im3.png\"\n",
    "import imageio\n",
    "import torch\n",
    "image_np = cv2.imread(image_path)\n",
    "image_tensor = torch.tensor(image_np).type(torch.FloatTensor).unsqueeze(0).permute(0,3,1,2)\n",
    "print(image_tensor.shape)\n",
    "\n",
    "o, m = warp(image_tensor, -of)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "target_path = \"/home/lrh/git/blind-denoising/tvl1flow/image/target/im4.png\"\n",
    "image_target = cv2.imread(target_path)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(221)\n",
    "plt.imshow(image_np)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(image_target)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(o[0].permute(1,2,0).numpy() / 255.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "img_file = '/home/lrh/git/blind-denoising/tvl1flow/image/target/im3.png'\n",
    "img2_file = '/home/lrh/git/blind-denoising/tvl1flow/image/target/im4.png'\n",
    "\n",
    "prev_frame =  cv2.imread(img_file)\n",
    "next_frame = cv2.imread(img2_file)\n",
    "\n",
    "flow_file = \"/home/lrh/git/blind-denoising/tvl1flow/of/tvl1_target.flo\"\n",
    "flow = read_flow(flow_file)\n",
    "\n",
    "def warp_flow(img, flow):\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = - flow\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "    res = cv2.remap(img, flow, None, cv2.INTER_LINEAR)\n",
    "    return res\n",
    "\n",
    "im2w = warp_flow(prev_frame, flow)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(221)\n",
    "plt.imshow(prev_frame / 255.0)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(next_frame/255.0)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(im2w/255.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/store/dataset/vdenoising/vimeo/input1/v1/frame_017_noisy.png'\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "img_pil = Image.open(data_path)\n",
    "print(img_pil)\n",
    "img = np.array(img_pil)\n",
    "print(img.shape)\n",
    "img = img[:,:,::-1]\n",
    "print(img.shape)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "from skimage import filters\n",
    "gaussian_img = filters.gaussian(img, sigma=1.5)\n",
    "\n",
    "plt.imshow(gaussian_img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#median_img = filters.median(img, np.ones((3, 3)))\n",
    "#plt.imshow(median_img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "\n",
    "a[::-1]\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread(data_path)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "blur = cv2.medianBlur(img,5)\n",
    "plt.imshow(blur)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numbers\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class GaussianSmoothing(nn.Module):\n",
    "    \"\"\"\n",
    "    Apply gaussian smoothing on a\n",
    "    1d, 2d or 3d tensor. Filtering is performed seperately for each channel\n",
    "    in the input using a depthwise convolution.\n",
    "    Arguments:\n",
    "        channels (int, sequence): Number of channels of the input tensors. Output will\n",
    "            have this number of channels as well.\n",
    "        kernel_size (int, sequence): Size of the gaussian kernel.\n",
    "        sigma (float, sequence): Standard deviation of the gaussian kernel.\n",
    "        dim (int, optional): The number of dimensions of the data.\n",
    "            Default value is 2 (spatial).\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, kernel_size=3, sigma=1.5, padding=1, dim=2):\n",
    "        super(GaussianSmoothing, self).__init__()\n",
    "        if isinstance(kernel_size, numbers.Number):\n",
    "            kernel_size = [kernel_size] * dim\n",
    "        if isinstance(sigma, numbers.Number):\n",
    "            sigma = [sigma] * dim\n",
    "\n",
    "        self.padding = padding\n",
    "\n",
    "        # print(kernel_size, sigma)\n",
    "        # The gaussian kernel is the product of the\n",
    "        # gaussian function of each dimension.\n",
    "        kernel = 1\n",
    "        meshgrids = torch.meshgrid(\n",
    "            [\n",
    "                torch.arange(size, dtype=torch.float32)\n",
    "                for size in kernel_size\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n",
    "            mean = (size - 1) / 2\n",
    "\n",
    "            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \\\n",
    "                      torch.exp(-((mgrid - mean) / (2 * std)) ** 2)\n",
    "\n",
    "        # Make sure sum of values in gaussian kernel equals 1.\n",
    "        kernel = kernel / torch.sum(kernel)\n",
    "\n",
    "\n",
    "        # Reshape to depthwise convolutional weight\n",
    "        kernel = kernel.view(1, 1, *kernel.size())\n",
    "        kernel = kernel.repeat(channels, *[1] * (kernel.dim() - 1))\n",
    "        #print(kernel.shape)\n",
    "        self.register_buffer('weight', kernel)\n",
    "        self.groups = channels\n",
    "\n",
    "        if dim == 1:\n",
    "            self.conv = F.conv1d\n",
    "        elif dim == 2:\n",
    "            self.conv = F.conv2d\n",
    "        elif dim == 3:\n",
    "            self.conv = F.conv3d\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                'Only 1, 2 and 3 dimensions are supported. Received {}.'.format(dim)\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Apply gaussian filter to input.\n",
    "        Arguments:\n",
    "            input (torch.Tensor): Input to apply gaussian filter on.\n",
    "        Returns:\n",
    "            filtered (torch.Tensor): Filtered output.\n",
    "        \"\"\"\n",
    "        return self.conv(input, weight=self.weight, padding=self.padding, groups=self.groups)\n",
    "\n",
    "smoothing = GaussianSmoothing(2, 5, 1.5, padding=2, dim=2)\n",
    "input = torch.rand(3, 2, 2, 100, 100)\n",
    "\n",
    "f, b, c, h, w = input.size()\n",
    "print(input.shape)\n",
    "\n",
    "input = input.view(f*b, c, h, w)\n",
    "print(input.shape)\n",
    "#input = F.pad(input, (2, 2, 2, 2), mode='reflect')\n",
    "output = smoothing(input)\n",
    "\n",
    "len(output.chunk(2, dim=2))\n",
    "\n",
    "t1, t2 = output.chunk(2, dim=2)\n",
    "\n",
    "print(t1.shape)\n",
    "print(t2.shape)\n",
    "\n",
    "#output = output.view(f, b, c, h, w)\n",
    "#print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(data_path) / 255.0\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "import torch\n",
    "img_tensor = torch.tensor(img).permute([2,0,1]).unsqueeze(0).type(torch.FloatTensor)\n",
    "\n",
    "smoothing = GaussianSmoothing(3, 7, 2, padding=2, dim=2)\n",
    "s_img_tensor = smoothing(img_tensor)\n",
    "\n",
    "s_img = s_img_tensor.squeeze().permute(1,2,0)\n",
    "plt.imshow(s_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.utils import _pair, _quadruple\n",
    "\n",
    "\n",
    "class MedianPool2d(nn.Module):\n",
    "    \"\"\" Median pool (usable as median filter when stride=1) module.\n",
    "    \n",
    "    Args:\n",
    "         kernel_size: size of pooling kernel, int or 2-tuple\n",
    "         stride: pool stride, int or 2-tuple\n",
    "         padding: pool padding, int or 4-tuple (l, r, t, b) as in pytorch F.pad\n",
    "         same: override padding and enforce same padding, boolean\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size=3, stride=1, padding=1, same=False):\n",
    "        super(MedianPool2d, self).__init__()\n",
    "        self.k = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.padding = _quadruple(padding)  # convert to l, r, t, b\n",
    "        self.same = same\n",
    "\n",
    "    def _padding(self, x):\n",
    "        if self.same:\n",
    "            ih, iw = x.size()[2:]\n",
    "            if ih % self.stride[0] == 0:\n",
    "                ph = max(self.k[0] - self.stride[0], 0)\n",
    "            else:\n",
    "                ph = max(self.k[0] - (ih % self.stride[0]), 0)\n",
    "            if iw % self.stride[1] == 0:\n",
    "                pw = max(self.k[1] - self.stride[1], 0)\n",
    "            else:\n",
    "                pw = max(self.k[1] - (iw % self.stride[1]), 0)\n",
    "            pl = pw // 2\n",
    "            pr = pw - pl\n",
    "            pt = ph // 2\n",
    "            pb = ph - pt\n",
    "            padding = (pl, pr, pt, pb)\n",
    "        else:\n",
    "            padding = self.padding\n",
    "        return padding\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # using existing pytorch functions and tensor ops so that we get autograd, \n",
    "        # would likely be more efficient to implement from scratch at C/Cuda level\n",
    "        x = F.pad(x, self._padding(x), mode='reflect')\n",
    "        x = x.unfold(2, self.k[0], self.stride[0]).unfold(3, self.k[1], self.stride[1])\n",
    "        x = x.contiguous().view(x.size()[:4] + (-1,)).median(dim=-1)[0]\n",
    "        return x\n",
    "\n",
    "    \n",
    "img = cv2.imread(data_path) / 255.0\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "import torch\n",
    "img_tensor = torch.tensor(img).permute([2,0,1]).unsqueeze(0).type(torch.FloatTensor)\n",
    "\n",
    "smoothing = MedianPool2d(kernel_size=5, padding=2)\n",
    "s_img_tensor = smoothing(img_tensor)\n",
    "\n",
    "print(s_img_tensor.shape)\n",
    "\n",
    "s_img = s_img_tensor.squeeze().permute(1,2,0)\n",
    "plt.imshow(s_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "import time\n",
    "\n",
    "while(True):\n",
    "    try:\n",
    "        DEVICE_ID_LIST = GPUtil.getFirstAvailable()\n",
    "        break;\n",
    "    except:\n",
    "        time.sleep(1)\n",
    "        print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-04f70d21278c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'python main.py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "command = 'python main.py'\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
